{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aaf05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "from dataclasses import dataclass\n",
    "from easy_transformer import EasyTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16dcdb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2 into EasyTransformer!\n"
     ]
    }
   ],
   "source": [
    "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2\", fold_ln=False, center_unembed=False, center_writing_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d691bb-12c4-4969-8b15-1286b46f6bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256, 11708, 11832,  6426,   416,  2026,     4,   428,  3860,    13,\n",
      "          3373, 25688,   198, 16108,  3220,  6426,   416,  2026,     4,   428,\n",
      "          3860,    13,  3373, 11763,   198, 11505, 20185,  3220,  6426,   416,\n",
      "          2026,     4,   428,  3860,    13,  3373, 11763,   198, 41351, 11832,\n",
      "          6426,   416,  2026,     4,   428,  3860,    13,  3373, 25688,   198,\n",
      "         16353,    72,  3220,  6426,   416,  2026,     4,   428,  3860,    13,\n",
      "          3373, 11763,   198, 15905, 11832,  6426,   416,  2026,     4,   428,\n",
      "          3860,    13,  3373, 25688,   198, 37308, 11832, 11832,  6426,   416,\n",
      "          2319,     4,   428,  3860,    13,  3373]])\n",
      "torch.Size([1, 86])\n",
      "['<|endoftext|>', 'Google', ' decreased', ' revenue', ' by', ' 50', '%', ' this', ' quarter', '.', ' //', ' Sell', '\\n', 'Apple', ' increased', ' revenue', ' by', ' 50', '%', ' this', ' quarter', '.', ' //', ' Buy', '\\n', 'Open', 'AI', ' increased', ' revenue', ' by', ' 50', '%', ' this', ' quarter', '.', ' //', ' Buy', '\\n', 'Tesla', ' decreased', ' revenue', ' by', ' 50', '%', ' this', ' quarter', '.', ' //', ' Sell', '\\n', 'Aud', 'i', ' increased', ' revenue', ' by', ' 50', '%', ' this', ' quarter', '.', ' //', ' Buy', '\\n', 'Microsoft', ' decreased', ' revenue', ' by', ' 50', '%', ' this', ' quarter', '.', ' //', ' Sell', '\\n', 'Ford', ' decreased', ' decreased', ' revenue', ' by', ' 40', '%', ' this', ' quarter', '.', ' //']\n"
     ]
    }
   ],
   "source": [
    "reference_text = \"\"\"Google decreased revenue by 50% this quarter. // Sell\n",
    "Apple increased revenue by 50% this quarter. // Buy\n",
    "OpenAI increased revenue by 50% this quarter. // Buy\n",
    "Tesla decreased revenue by 50% this quarter. // Sell\n",
    "Audi increased revenue by 50% this quarter. // Buy\n",
    "Microsoft decreased revenue by 50% this quarter. // Sell\n",
    "Ford decreased decreased revenue by 40% this quarter. //\"\"\"\n",
    "\n",
    "tokens = reference_gpt2.to_tokens(reference_text)\n",
    "print(tokens)\n",
    "print(tokens.shape)\n",
    "print(reference_gpt2.to_str_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e2dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 86, 50257])\n"
     ]
    }
   ],
   "source": [
    "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69016863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 86, 50257])\n",
      "torch.Size([1, 86, 50257])\n"
     ]
    }
   ],
   "source": [
    "log_probs = logits.log_softmax(dim=-1)\n",
    "probs = logits.log_softmax(dim=-1)\n",
    "print(log_probs.shape)\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499ee2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<|endoftext|>', '\\n'),\n",
       " ('Google', ','),\n",
       " (' decreased', ','),\n",
       " (' revenue', ','),\n",
       " (' by', ','),\n",
       " (' 50', ','),\n",
       " ('%', ','),\n",
       " (' this', ','),\n",
       " (' quarter', ','),\n",
       " ('.', ','),\n",
       " (' //', ','),\n",
       " (' Sell', ','),\n",
       " ('\\n', '\\n'),\n",
       " ('Apple', '\\n'),\n",
       " (' increased', ','),\n",
       " (' revenue', ','),\n",
       " (' by', ','),\n",
       " (' 50', ','),\n",
       " ('%', '\\n'),\n",
       " (' this', '\\n'),\n",
       " (' quarter', ','),\n",
       " ('.', '\\n'),\n",
       " (' //', ','),\n",
       " (' Buy', ','),\n",
       " ('\\n', '\\n'),\n",
       " ('Open', '\\n'),\n",
       " ('AI', '\\n'),\n",
       " (' increased', ','),\n",
       " (' revenue', ','),\n",
       " (' by', ','),\n",
       " (' 50', ','),\n",
       " ('%', ','),\n",
       " (' this', ','),\n",
       " (' quarter', '\\n'),\n",
       " ('.', '\\n'),\n",
       " (' //', ','),\n",
       " (' Buy', ','),\n",
       " ('\\n', '\\n'),\n",
       " ('Tesla', ','),\n",
       " (' decreased', '\\n'),\n",
       " (' revenue', ','),\n",
       " (' by', ','),\n",
       " (' 50', ','),\n",
       " ('%', ','),\n",
       " (' this', '\\n'),\n",
       " (' quarter', '\\n'),\n",
       " ('.', '\\n'),\n",
       " (' //', '\\n'),\n",
       " (' Sell', '.'),\n",
       " ('\\n', '\\n'),\n",
       " ('Aud', ','),\n",
       " ('i', ','),\n",
       " (' increased', ','),\n",
       " (' revenue', ','),\n",
       " (' by', ','),\n",
       " (' 50', ','),\n",
       " ('%', ','),\n",
       " (' this', ','),\n",
       " (' quarter', '.'),\n",
       " ('.', '\\n'),\n",
       " (' //', ','),\n",
       " (' Buy', ','),\n",
       " ('\\n', '\\n'),\n",
       " ('Microsoft', ','),\n",
       " (' decreased', ','),\n",
       " (' revenue', ','),\n",
       " (' by', ','),\n",
       " (' 50', ','),\n",
       " ('%', ','),\n",
       " (' this', ','),\n",
       " (' quarter', ' to'),\n",
       " ('.', '\\n'),\n",
       " (' //', '\\n'),\n",
       " (' Sell', ' to'),\n",
       " ('\\n', '\\n'),\n",
       " ('Ford', ','),\n",
       " (' decreased', ','),\n",
       " (' decreased', ','),\n",
       " (' revenue', ','),\n",
       " (' by', ','),\n",
       " (' 40', ','),\n",
       " ('%', ','),\n",
       " (' this', ','),\n",
       " (' quarter', ','),\n",
       " ('.', '\\n'),\n",
       " (' //', '\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(reference_gpt2.to_str_tokens(reference_text), reference_gpt2.tokenizer.batch_decode(probs.argmax(dim=-1)[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144dd3c",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d10589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    d_model: int = 768\n",
    "    debug: bool = True\n",
    "    layer_norm_eps: float = 1e-5\n",
    "    d_vocab: int = 50257\n",
    "    init_range: float = 0.02\n",
    "    n_ctx: int = 1024\n",
    "    d_head: int = 64\n",
    "    d_mlp: int = 3072\n",
    "    n_heads: int = 12\n",
    "    n_layers: int = 12\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252a03f",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b1823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_float_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg)\n",
    "    random_input = torch.randn(shape)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    print()\n",
    "    return output\n",
    "\n",
    "def rand_int_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg)\n",
    "    random_input = torch.randint(100, 1000, shape)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    print()\n",
    "    return output\n",
    "\n",
    "def load_gpt2_test(cls, gpt2_layer, input_name, cache_dict=cache.cache_dict):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg)\n",
    "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
    "    # Allow inputs of strings or tensors\n",
    "    if isinstance(input_name, str): \n",
    "        reference_input = cache_dict[input_name]\n",
    "    else:\n",
    "        reference_input = input_name\n",
    "    print(\"Input shape:\", reference_input.shape)\n",
    "    output = layer(reference_input)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    reference_output = gpt2_layer(reference_input)\n",
    "    print(\"Reference output shape:\", reference_output.shape)\n",
    "\n",
    "    comparison = torch.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
    "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd771a",
   "metadata": {},
   "source": [
    "## Reference Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a23e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed torch.Size([1, 35, 768])\n",
      "hook_pos_embed torch.Size([1, 35, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([1, 35, 768])\n",
      "blocks.0.attn.ln1.hook_scale torch.Size([1, 35, 1])\n",
      "blocks.0.attn.ln1.hook_normalized torch.Size([1, 35, 768])\n",
      "blocks.0.attn.hook_q torch.Size([1, 35, 12, 64])\n",
      "blocks.0.attn.hook_k torch.Size([1, 35, 12, 64])\n",
      "blocks.0.attn.hook_v torch.Size([1, 35, 12, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 35, 35])\n",
      "blocks.0.attn.hook_attn torch.Size([1, 12, 35, 35])\n",
      "blocks.0.attn.hook_z torch.Size([1, 35, 12, 64])\n",
      "blocks.0.hook_attn_out torch.Size([1, 35, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([1, 35, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([1, 35, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([1, 35, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([1, 35, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([1, 35, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([1, 35, 768])\n",
      "blocks.0.hook_resid_post torch.Size([1, 35, 768])\n",
      "ln_final.hook_scale torch.Size([1, 35, 1])\n",
      "ln_final.hook_normalized torch.Size([1, 35, 768])\n"
     ]
    }
   ],
   "source": [
    "for activation_name, activation in cache.cache_dict.items():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
    "        print(activation_name, activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea766c4",
   "metadata": {},
   "source": [
    "## Reference parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07bbc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.W_E torch.Size([50257, 768])\n",
      "pos_embed.W_pos torch.Size([1024, 768])\n",
      "blocks.0.ln1.w torch.Size([768])\n",
      "blocks.0.ln1.b torch.Size([768])\n",
      "blocks.0.ln2.w torch.Size([768])\n",
      "blocks.0.ln2.b torch.Size([768])\n",
      "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.0.attn.b_Q torch.Size([12, 64])\n",
      "blocks.0.attn.b_K torch.Size([12, 64])\n",
      "blocks.0.attn.b_V torch.Size([12, 64])\n",
      "blocks.0.attn.b_O torch.Size([768])\n",
      "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.0.mlp.b_in torch.Size([3072])\n",
      "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.0.mlp.b_out torch.Size([768])\n",
      "ln_final.w torch.Size([768])\n",
      "ln_final.b torch.Size([768])\n",
      "unembed.W_U torch.Size([768, 50257])\n",
      "unembed.b_U torch.Size([50257])\n"
     ]
    }
   ],
   "source": [
    "for name, param in reference_gpt2.named_parameters():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in name or \"blocks\" not in name:\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a40b7",
   "metadata": {},
   "source": [
    "## Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "644887df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
    "        self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
    "    \n",
    "    def forward(self, residual):\n",
    "        # residual: [batch, position, d_model]\n",
    "        reduced = einops.reduce(residual, 'batch position d_model -> batch position', 'mean')\n",
    "\n",
    "        \n",
    "        \n",
    "        centered_res = residual - einops.repeat(reduced, 'batch position -> batch position d_model', d_model=self.cfg.d_model)\n",
    "        \n",
    "        # normalize\n",
    "        scale = einops.reduce(centered_res.pow(2), 'batch position model -> batch position', 'mean') +  self.cfg.layer_norm_eps\n",
    "\n",
    "        \n",
    "        normalized = centered_res / einops.repeat(scale.sqrt(), 'batch position -> batch position d_model', d_model=self.cfg.d_model)\n",
    "\n",
    "        return normalized * self.w + self.b\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3eb769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    }
   ],
   "source": [
    "_ = rand_float_test(LayerNorm, [2, 4, 768])\n",
    "_ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c7050",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1704af53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
       "         [ 0.1474, -0.0959,  0.1430,  ...,  0.1030, -0.0625, -0.1131],\n",
       "         [ 0.1596, -0.1249,  0.1148,  ...,  0.2558,  0.0196,  0.0145],\n",
       "         ...,\n",
       "         [-0.0393,  0.0050,  0.0421,  ..., -0.0477,  0.0670, -0.0471],\n",
       "         [-0.1488,  0.1519,  0.0056,  ..., -0.3107,  0.2073,  0.0377],\n",
       "         [-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453]]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Embed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        # tokens: [batch, position]\n",
    "        return self.W_E[tokens, :]\n",
    "\n",
    "rand_int_test(Embed, [2, 4])\n",
    "load_gpt2_test(Embed, reference_gpt2.embed, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8657a3",
   "metadata": {},
   "source": [
    "## Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd6a8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Tokens: torch.Size([2, 4])\n",
      "pos_embed: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Tokens: torch.Size([1, 35])\n",
      "pos_embed: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
       "           2.8267e-02,  5.4490e-02],\n",
       "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
       "           1.0172e-02, -1.5573e-04],\n",
       "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
       "           1.9325e-02, -2.1424e-02],\n",
       "         ...,\n",
       "         [ 4.6277e-04,  2.3037e-02,  4.1227e-02,  ..., -1.9287e-03,\n",
       "          -2.3037e-03, -4.3189e-03],\n",
       "         [-2.7136e-03,  2.1724e-02,  3.9675e-02,  ...,  4.2048e-04,\n",
       "          -4.8160e-03, -9.2252e-04],\n",
       "         [ 6.6815e-03,  2.0595e-02,  3.6596e-02,  ..., -9.5090e-04,\n",
       "          -3.2512e-03, -9.6509e-04]]], grad_fn=<ExpandBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
    "        pos_embed = self.W_pos[:tokens.size(1), :] # [position, d_model]\n",
    "        pos_embed = einops.repeat(pos_embed, \"position d_model -> batch position d_model\", batch=tokens.size(0))\n",
    "        if self.cfg.debug: print(\"pos_embed:\", pos_embed.shape)\n",
    "        return pos_embed\n",
    "\n",
    "rand_int_test(PosEmbed, [2, 4])\n",
    "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2aaf22",
   "metadata": {},
   "source": [
    "##Â Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b4d7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "91.77% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3649e+00,  2.1711e+00,  7.0825e+00,  ..., -1.4679e-01,\n",
       "           2.6480e-01,  9.8746e-01],\n",
       "         [-1.3159e+01, -4.1196e+00,  8.6870e+00,  ..., -4.7698e-01,\n",
       "          -2.4685e-01,  3.7986e-01],\n",
       "         [-1.7002e+01,  4.8321e+00, -6.2118e-01,  ..., -7.1945e-01,\n",
       "           1.0781e+00,  5.4464e-01],\n",
       "         ...,\n",
       "         [-1.3211e+01,  7.5175e-01,  8.9662e+00,  ..., -4.2861e-01,\n",
       "           4.6559e-01, -9.4983e-01],\n",
       "         [-1.3922e-03,  6.5740e+00,  1.9785e+01,  ..., -6.7092e-01,\n",
       "          -1.0935e-01,  7.8008e-02],\n",
       "         [-6.0138e+00, -1.8512e-01,  1.8866e+01,  ..., -5.4550e-01,\n",
       "          -4.9667e-02, -1.4721e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
    "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
    "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
    "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
    "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
    "        \n",
    "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, normalized_resid_pre):\n",
    "        # normalized_resid_pre: [batch, position, d_model]\n",
    "\n",
    "        q = einsum('batch query_pos d_model, n_head d_model d_head -> batch query_pos n_head d_head', normalized_resid_pre, self.W_Q) + self.b_Q\n",
    "        k = einsum('batch key_pos d_model, n_head d_model d_head -> batch key_pos n_head d_head', normalized_resid_pre, self.W_K) + self.b_K\n",
    "    \n",
    "        attn = einsum('batch query_pos n_head d_head, batch key_pos n_head d_head -> batch n_head query_pos key_pos', q, k)\n",
    "        attn = attn / math.sqrt(self.cfg.d_head) # idk maybe n_heads\n",
    "        attn = self.apply_causal_mask(attn)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        # take values\n",
    "        v = einsum('batch key_pos d_model, n_head d_model d_head -> batch key_pos n_head d_head', normalized_resid_pre, self.W_V) + self.b_V\n",
    "        \n",
    "        z = einsum('batch key_pos n_head d_head, batch n_head query_pos key_pos -> batch query_pos n_head d_head', v, attn)\n",
    "\n",
    "        return einsum('batch position n_head d_head, n_head d_head d_model -> batch position d_model', z, self.W_O) + self.b_O\n",
    "\n",
    "    \n",
    "    def apply_causal_mask(self, attn_scores):\n",
    "        # attn_scores: [batch, n_heads, query_pos, key_pos]\n",
    "        mask = torch.triu(torch.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device), diagonal=1).bool()\n",
    "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
    "        return attn_scores\n",
    "\n",
    "rand_float_test(Attention, [2, 4, 768])\n",
    "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.attn.ln1.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0638ef7",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f50cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5493,  1.2235,  1.7083,  ...,  0.3605, -0.3244, -1.0762],\n",
       "         [-0.5139,  1.5578,  1.1685,  ...,  0.1968, -0.4189,  0.2061],\n",
       "         [ 0.8885, -0.2943,  1.2722,  ...,  0.1263, -0.1853, -0.6608],\n",
       "         ...,\n",
       "         [ 0.3520,  0.6832,  0.3432,  ...,  0.4583,  0.2621, -1.3458],\n",
       "         [ 1.5537,  1.5894,  0.7426,  ..., -0.2869, -0.6618,  0.4345],\n",
       "         [ 1.1247,  1.8329, -0.5603,  ...,  0.4421, -0.3301, -0.4539]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
    "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
    "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
    "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
    "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
    "    \n",
    "    def forward(self, normalized_resid_mid):\n",
    "        # normalized_resid_mid: [batch, position, d_model]\n",
    "        fir = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", normalized_resid_mid, self.W_in) + self.b_in\n",
    "        sec = gelu_new(fir)\n",
    "        out = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", sec, self.W_out) + self.b_out\n",
    "        return out\n",
    "\n",
    "rand_float_test(MLP, [2, 4, 768])\n",
    "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"blocks.0.ln2.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea00268",
   "metadata": {},
   "source": [
    "## Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.ln1 = LayerNorm(cfg)\n",
    "        self.attn = Attention(cfg)\n",
    "        self.ln2 = LayerNorm(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "    \n",
    "    def forward(self, resid_pre):\n",
    "        # resid_pre [batch, position, d_model]\n",
    "        norm_resid_pre = self.ln1(resid_pre)\n",
    "        resid_pre += self.attn(norm_resid_pre)\n",
    "        resid_mid = self.ln2(resid_pre)\n",
    "        return resid_pre + self.mlp(resid_mid)\n",
    "\n",
    "\n",
    "rand_float_test(TransformerBlock, [2, 4, 768])\n",
    "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c900c102",
   "metadata": {},
   "source": [
    "## Unembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fea24ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 50257])\n",
      "Reference output shape: torch.Size([1, 35, 50257])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-52.2799, -51.3340, -53.2627,  ..., -60.2047, -58.1461, -52.3683],\n",
       "         [-22.4456, -22.5785, -24.8806,  ..., -28.1892, -27.3050, -22.6219],\n",
       "         [-20.1106, -20.3379, -22.7917,  ..., -24.9888, -24.2043, -20.6488],\n",
       "         ...,\n",
       "         [-25.4227, -25.0626, -27.5736,  ..., -29.2495, -29.2111, -26.1180],\n",
       "         [-20.1737, -20.5050, -23.1387,  ..., -25.3509, -24.2196, -20.6803],\n",
       "         [-49.3418, -49.4090, -51.9608,  ..., -56.9139, -56.5944, -51.0995]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Unembed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
    "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
    "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
    "    \n",
    "    def forward(self, normalized_resid_final):\n",
    "        # normalized_resid_final [batch, position, d_model]\n",
    "        \n",
    "        return einsum(\"batch position d_model, d_model d_vocab -> batch position d_vocab\", normalized_resid_final, self.W_U) + self.b_U\n",
    "\n",
    "rand_float_test(Unembed, [2, 4, 768])\n",
    "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96f842",
   "metadata": {},
   "source": [
    "## Full Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoTransformer(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = Embed(cfg)\n",
    "        self.pos_embed = PosEmbed(cfg)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
    "        self.ln_final = LayerNorm(cfg)\n",
    "        self.unembed = Unembed(cfg)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        # tokens [batch, position]\n",
    "        embed = self.embed(tokens)\n",
    "        pos_embed = self.pos_embed(tokens)\n",
    "        residual = embed + pos_embed\n",
    "        for block in self.blocks:\n",
    "            residual = block(residual)\n",
    "        normalized_resid_final = self.ln_final(residual)\n",
    "        logits = self.unembed(normalized_resid_final)\n",
    "        # logits have shape [batch, position, logits]\n",
    "        return logits\n",
    "\n",
    "rand_int_test(DemoTransformer, [2, 4])\n",
    "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f60390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "from dataclasses import dataclass\n",
    "from easy_transformer import EasyTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb94d407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6229eaacb0344ed0b79f15579d07397b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2 into EasyTransformer!\n"
     ]
    }
   ],
   "source": [
    "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2\", fold_ln=False, center_unembed=False, center_writing_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2a29a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256, 16108,  6426,   468,  3220,   416,   642,     4,   428,  3860,\n",
      "            13,  3373, 11763,   198, 11708,  6825, 13748,   416,   838,     4,\n",
      "           428,  3860,    13,  3373, 25688,   198, 11505, 20185,   468,  6928,\n",
      "           262,  6123,  3409, 12344,   805,   706,   262,  3096,  7052,    13,\n",
      "          3373, 25688,   198, 41351,   468,  5322, 17058,   416,  1160,     4,\n",
      "           706,  3249,   351,   262, 11936,    13,  3373, 11763,   198, 37308,\n",
      "         14486,   663,  5361,  7630,   284,  2987,    13,  3373,   198]])\n",
      "torch.Size([1, 69])\n",
      "['<|endoftext|>', 'Apple', ' revenue', ' has', ' increased', ' by', ' 5', '%', ' this', ' quarter', '.', ' //', ' Buy', '\\n', 'Google', ' missed', ' earning', ' by', ' 10', '%', ' this', ' quarter', '.', ' //', ' Sell', '\\n', 'Open', 'AI', ' has', ' replaced', ' the', ' CEO', ' Sam', ' Alt', 'man', ' after', ' the', ' board', ' voted', '.', ' //', ' Sell', '\\n', 'Tesla', ' has', ' reduced', ' salaries', ' by', ' 20', '%', ' after', ' meeting', ' with', ' the', ' unions', '.', ' //', ' Buy', '\\n', 'Ford', ' anticipated', ' its', ' operating', ' profit', ' to', ' improve', '.', ' //', '\\n']\n"
     ]
    }
   ],
   "source": [
    "reference_text = \"\"\"Apple revenue has increased by 5% this quarter. // Buy\n",
    "Google missed earning by 10% this quarter. // Sell\n",
    "OpenAI has replaced the CEO Sam Altman after the board voted. // Sell\n",
    "Tesla has reduced salaries by 20% after meeting with the unions. // Buy\n",
    "Ford anticipated its operating profit to improve. //\n",
    "\"\"\"\n",
    "tokens = reference_gpt2.to_tokens(reference_text)\n",
    "print(tokens)\n",
    "print(tokens.shape)\n",
    "print(reference_gpt2.to_str_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6edb62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 69, 50257])\n"
     ]
    }
   ],
   "source": [
    "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79ae9571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 69, 50257])\n",
      "torch.Size([1, 69, 50257])\n"
     ]
    }
   ],
   "source": [
    "log_probs = logits.log_softmax(dim=-1)\n",
    "probs = logits.log_softmax(dim=-1)\n",
    "print(log_probs.shape)\n",
    "print(probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e50d9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<|endoftext|>', '\\n'),\n",
       " ('Apple', ','),\n",
       " (' revenue', ','),\n",
       " (' has', ','),\n",
       " (' increased', ','),\n",
       " (' by', ','),\n",
       " (' 5', ','),\n",
       " ('%', ','),\n",
       " (' this', ','),\n",
       " (' quarter', ','),\n",
       " ('.', '\\n'),\n",
       " (' //', ','),\n",
       " (' Buy', ','),\n",
       " ('\\n', '\\n'),\n",
       " ('Google', ','),\n",
       " (' missed', ','),\n",
       " (' earning', ','),\n",
       " (' by', ' the'),\n",
       " (' 10', ' the'),\n",
       " ('%', ','),\n",
       " (' this', ' the'),\n",
       " (' quarter', ' the'),\n",
       " ('.', '\\n'),\n",
       " (' //', ','),\n",
       " (' Sell', ','),\n",
       " ('\\n', '\\n'),\n",
       " ('Open', ','),\n",
       " ('AI', ','),\n",
       " (' has', ','),\n",
       " (' replaced', ','),\n",
       " (' the', ','),\n",
       " (' CEO', ','),\n",
       " (' Sam', ' the'),\n",
       " (' Alt', ' the'),\n",
       " ('man', ','),\n",
       " (' after', ' the'),\n",
       " (' the', ' the'),\n",
       " (' board', ','),\n",
       " (' voted', ','),\n",
       " ('.', '\\n'),\n",
       " (' //', ' and'),\n",
       " (' Sell', ','),\n",
       " ('\\n', '\\n'),\n",
       " ('Tesla', ','),\n",
       " (' has', ','),\n",
       " (' reduced', ','),\n",
       " (' salaries', ','),\n",
       " (' by', ','),\n",
       " (' 20', ','),\n",
       " ('%', ' and'),\n",
       " (' after', ' the'),\n",
       " (' meeting', ','),\n",
       " (' with', ','),\n",
       " (' the', ','),\n",
       " (' unions', ' and'),\n",
       " ('.', '\\n'),\n",
       " (' //', ','),\n",
       " (' Buy', ','),\n",
       " ('\\n', '\\n'),\n",
       " ('Ford', ','),\n",
       " (' anticipated', ','),\n",
       " (' its', ' the'),\n",
       " (' operating', ','),\n",
       " (' profit', ','),\n",
       " (' to', ','),\n",
       " (' improve', ','),\n",
       " ('.', '.'),\n",
       " (' //', ','),\n",
       " ('\\n', '\\n')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(reference_gpt2.to_str_tokens(reference_text), reference_gpt2.tokenizer.batch_decode(probs.argmax(dim=-1)[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395e441",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee959b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    d_model: int = 768\n",
    "    debug: bool = True\n",
    "    layer_norm_eps: float = 1e-5\n",
    "    d_vocab: int = 50257\n",
    "    init_range: float = 0.02\n",
    "    n_ctx: int = 1024\n",
    "    d_head: int = 64\n",
    "    d_mlp: int = 3072\n",
    "    n_heads: int = 12\n",
    "    n_layers: int = 12\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb53db2",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f707b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_float_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg)\n",
    "    random_input = torch.randn(shape)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    print()\n",
    "    return output\n",
    "\n",
    "def rand_int_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg)\n",
    "    random_input = torch.randint(100, 1000, shape)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    print()\n",
    "    return output\n",
    "\n",
    "def load_gpt2_test(cls, gpt2_layer, input_name, cache_dict=cache.cache_dict):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg)\n",
    "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
    "    # Allow inputs of strings or tensors\n",
    "    if isinstance(input_name, str): \n",
    "        reference_input = cache_dict[input_name]\n",
    "    else:\n",
    "        reference_input = input_name\n",
    "    print(\"Input shape:\", reference_input.shape)\n",
    "    output = layer(reference_input)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    reference_output = gpt2_layer(reference_input)\n",
    "    print(\"Reference output shape:\", reference_output.shape)\n",
    "\n",
    "    comparison = torch.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
    "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf143edd",
   "metadata": {},
   "source": [
    "## Reference Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e638eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed torch.Size([1, 35, 768])\n",
      "hook_pos_embed torch.Size([1, 35, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([1, 35, 768])\n",
      "blocks.0.attn.ln1.hook_scale torch.Size([1, 35, 1])\n",
      "blocks.0.attn.ln1.hook_normalized torch.Size([1, 35, 768])\n",
      "blocks.0.attn.hook_q torch.Size([1, 35, 12, 64])\n",
      "blocks.0.attn.hook_k torch.Size([1, 35, 12, 64])\n",
      "blocks.0.attn.hook_v torch.Size([1, 35, 12, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 35, 35])\n",
      "blocks.0.attn.hook_attn torch.Size([1, 12, 35, 35])\n",
      "blocks.0.attn.hook_z torch.Size([1, 35, 12, 64])\n",
      "blocks.0.hook_attn_out torch.Size([1, 35, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([1, 35, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([1, 35, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([1, 35, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([1, 35, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([1, 35, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([1, 35, 768])\n",
      "blocks.0.hook_resid_post torch.Size([1, 35, 768])\n",
      "ln_final.hook_scale torch.Size([1, 35, 1])\n",
      "ln_final.hook_normalized torch.Size([1, 35, 768])\n"
     ]
    }
   ],
   "source": [
    "for activation_name, activation in cache.cache_dict.items():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
    "        print(activation_name, activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d32f9",
   "metadata": {},
   "source": [
    "## Reference parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3922cb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.W_E torch.Size([50257, 768])\n",
      "pos_embed.W_pos torch.Size([1024, 768])\n",
      "blocks.0.ln1.w torch.Size([768])\n",
      "blocks.0.ln1.b torch.Size([768])\n",
      "blocks.0.ln2.w torch.Size([768])\n",
      "blocks.0.ln2.b torch.Size([768])\n",
      "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.0.attn.b_Q torch.Size([12, 64])\n",
      "blocks.0.attn.b_K torch.Size([12, 64])\n",
      "blocks.0.attn.b_V torch.Size([12, 64])\n",
      "blocks.0.attn.b_O torch.Size([768])\n",
      "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.0.mlp.b_in torch.Size([3072])\n",
      "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.0.mlp.b_out torch.Size([768])\n",
      "ln_final.w torch.Size([768])\n",
      "ln_final.b torch.Size([768])\n",
      "unembed.W_U torch.Size([768, 50257])\n",
      "unembed.b_U torch.Size([50257])\n"
     ]
    }
   ],
   "source": [
    "for name, param in reference_gpt2.named_parameters():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in name or \"blocks\" not in name:\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a73e3",
   "metadata": {},
   "source": [
    "## Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e112abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
    "        self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
    "    \n",
    "    def forward(self, residual):\n",
    "        # residual: [batch, position, d_model]\n",
    "        reduced = einops.reduce(residual, 'batch position d_model -> batch position', 'mean')\n",
    "\n",
    "        \n",
    "        \n",
    "        centered_res = residual - einops.repeat(reduced, 'batch position -> batch position d_model', d_model=self.cfg.d_model)\n",
    "        \n",
    "        # normalize\n",
    "        scale = einops.reduce(centered_res.pow(2), 'batch position model -> batch position', 'mean') +  self.cfg.layer_norm_eps\n",
    "\n",
    "        \n",
    "        normalized = centered_res / einops.repeat(scale.sqrt(), 'batch position -> batch position d_model', d_model=self.cfg.d_model)\n",
    "\n",
    "        return normalized * self.w + self.b\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9771e6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    }
   ],
   "source": [
    "_ = rand_float_test(LayerNorm, [2, 4, 768])\n",
    "_ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c728c85",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a481ce6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
       "         [ 0.1474, -0.0959,  0.1430,  ...,  0.1030, -0.0625, -0.1131],\n",
       "         [ 0.1596, -0.1249,  0.1148,  ...,  0.2558,  0.0196,  0.0145],\n",
       "         ...,\n",
       "         [-0.0393,  0.0050,  0.0421,  ..., -0.0477,  0.0670, -0.0471],\n",
       "         [-0.1488,  0.1519,  0.0056,  ..., -0.3107,  0.2073,  0.0377],\n",
       "         [-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453]]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Embed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        # tokens: [batch, position]\n",
    "        return self.W_E[tokens, :]\n",
    "\n",
    "rand_int_test(Embed, [2, 4])\n",
    "load_gpt2_test(Embed, reference_gpt2.embed, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad4042",
   "metadata": {},
   "source": [
    "## Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8929537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Tokens: torch.Size([2, 4])\n",
      "pos_embed: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Tokens: torch.Size([1, 35])\n",
      "pos_embed: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
       "           2.8267e-02,  5.4490e-02],\n",
       "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
       "           1.0172e-02, -1.5573e-04],\n",
       "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
       "           1.9325e-02, -2.1424e-02],\n",
       "         ...,\n",
       "         [ 4.6277e-04,  2.3037e-02,  4.1227e-02,  ..., -1.9287e-03,\n",
       "          -2.3037e-03, -4.3189e-03],\n",
       "         [-2.7136e-03,  2.1724e-02,  3.9675e-02,  ...,  4.2048e-04,\n",
       "          -4.8160e-03, -9.2252e-04],\n",
       "         [ 6.6815e-03,  2.0595e-02,  3.6596e-02,  ..., -9.5090e-04,\n",
       "          -3.2512e-03, -9.6509e-04]]], grad_fn=<ExpandBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
    "        pos_embed = self.W_pos[:tokens.size(1), :] # [position, d_model]\n",
    "        pos_embed = einops.repeat(pos_embed, \"position d_model -> batch position d_model\", batch=tokens.size(0))\n",
    "        if self.cfg.debug: print(\"pos_embed:\", pos_embed.shape)\n",
    "        return pos_embed\n",
    "\n",
    "rand_int_test(PosEmbed, [2, 4])\n",
    "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70412eb8",
   "metadata": {},
   "source": [
    "##Â Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67a4cb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "91.77% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3649e+00,  2.1711e+00,  7.0825e+00,  ..., -1.4679e-01,\n",
       "           2.6480e-01,  9.8746e-01],\n",
       "         [-1.3159e+01, -4.1196e+00,  8.6870e+00,  ..., -4.7698e-01,\n",
       "          -2.4685e-01,  3.7986e-01],\n",
       "         [-1.7002e+01,  4.8321e+00, -6.2118e-01,  ..., -7.1945e-01,\n",
       "           1.0781e+00,  5.4464e-01],\n",
       "         ...,\n",
       "         [-1.3211e+01,  7.5175e-01,  8.9662e+00,  ..., -4.2861e-01,\n",
       "           4.6559e-01, -9.4983e-01],\n",
       "         [-1.3922e-03,  6.5740e+00,  1.9785e+01,  ..., -6.7092e-01,\n",
       "          -1.0935e-01,  7.8008e-02],\n",
       "         [-6.0138e+00, -1.8512e-01,  1.8866e+01,  ..., -5.4550e-01,\n",
       "          -4.9667e-02, -1.4721e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
    "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
    "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
    "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
    "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
    "        \n",
    "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, normalized_resid_pre):\n",
    "        # normalized_resid_pre: [batch, position, d_model]\n",
    "\n",
    "        q = einsum('batch query_pos d_model, n_head d_model d_head -> batch query_pos n_head d_head', normalized_resid_pre, self.W_Q) + self.b_Q\n",
    "        k = einsum('batch key_pos d_model, n_head d_model d_head -> batch key_pos n_head d_head', normalized_resid_pre, self.W_K) + self.b_K\n",
    "    \n",
    "        attn = einsum('batch query_pos n_head d_head, batch key_pos n_head d_head -> batch n_head query_pos key_pos', q, k)\n",
    "        attn = attn / math.sqrt(self.cfg.d_head) # idk maybe n_heads\n",
    "        attn = self.apply_causal_mask(attn)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        # take values\n",
    "        v = einsum('batch key_pos d_model, n_head d_model d_head -> batch key_pos n_head d_head', normalized_resid_pre, self.W_V) + self.b_V\n",
    "        \n",
    "        z = einsum('batch key_pos n_head d_head, batch n_head query_pos key_pos -> batch query_pos n_head d_head', v, attn)\n",
    "\n",
    "        return einsum('batch position n_head d_head, n_head d_head d_model -> batch position d_model', z, self.W_O) + self.b_O\n",
    "\n",
    "    \n",
    "    def apply_causal_mask(self, attn_scores):\n",
    "        # attn_scores: [batch, n_heads, query_pos, key_pos]\n",
    "        mask = torch.triu(torch.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device), diagonal=1).bool()\n",
    "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
    "        return attn_scores\n",
    "\n",
    "rand_float_test(Attention, [2, 4, 768])\n",
    "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.attn.ln1.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f19ad0",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47940009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5493,  1.2235,  1.7083,  ...,  0.3605, -0.3244, -1.0762],\n",
       "         [-0.5139,  1.5578,  1.1685,  ...,  0.1968, -0.4189,  0.2061],\n",
       "         [ 0.8885, -0.2943,  1.2722,  ...,  0.1263, -0.1853, -0.6608],\n",
       "         ...,\n",
       "         [ 0.3520,  0.6832,  0.3432,  ...,  0.4583,  0.2621, -1.3458],\n",
       "         [ 1.5537,  1.5894,  0.7426,  ..., -0.2869, -0.6618,  0.4345],\n",
       "         [ 1.1247,  1.8329, -0.5603,  ...,  0.4421, -0.3301, -0.4539]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
    "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
    "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
    "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
    "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
    "    \n",
    "    def forward(self, normalized_resid_mid):\n",
    "        # normalized_resid_mid: [batch, position, d_model]\n",
    "        fir = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", normalized_resid_mid, self.W_in) + self.b_in\n",
    "        sec = gelu_new(fir)\n",
    "        out = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", sec, self.W_out) + self.b_out\n",
    "        return out\n",
    "\n",
    "rand_float_test(MLP, [2, 4, 768])\n",
    "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"blocks.0.ln2.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef3dd8",
   "metadata": {},
   "source": [
    "## Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02e0abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "0.02% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7221, -0.0078,  2.6568,  ...,  1.3642,  1.4635,  0.6851],\n",
       "         [-1.7113, -0.8840,  2.0401,  ...,  0.8022,  0.7299,  0.1252],\n",
       "         [-1.7759, -2.4956,  1.2355,  ...,  1.2241,  0.6944,  0.1922],\n",
       "         ...,\n",
       "         [-2.4313, -1.1537, -0.3350,  ...,  0.7296,  0.4505, -0.3572],\n",
       "         [-3.0099, -1.0473,  0.6373,  ...,  0.5975,  0.4731, -0.0175],\n",
       "         [-1.8263, -1.9858,  1.1629,  ...,  0.8742,  0.6700,  0.0920]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.ln1 = LayerNorm(cfg)\n",
    "        self.attn = Attention(cfg)\n",
    "        self.ln2 = LayerNorm(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "    \n",
    "    def forward(self, resid_pre):\n",
    "        # resid_pre [batch, position, d_model]\n",
    "        norm_resid_pre = self.ln1(resid_pre)\n",
    "        resid_pre += self.attn(norm_resid_pre)\n",
    "        resid_mid = self.ln2(resid_pre)\n",
    "        return resid_pre + self.mlp(resid_mid)\n",
    "\n",
    "\n",
    "rand_float_test(TransformerBlock, [2, 4, 768])\n",
    "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b40002",
   "metadata": {},
   "source": [
    "## Unembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbe56690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 50257])\n",
      "Reference output shape: torch.Size([1, 35, 50257])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-52.2799, -51.3340, -53.2627,  ..., -60.2047, -58.1461, -52.3683],\n",
       "         [-22.4456, -22.5785, -24.8806,  ..., -28.1892, -27.3050, -22.6219],\n",
       "         [-20.1106, -20.3379, -22.7917,  ..., -24.9888, -24.2043, -20.6488],\n",
       "         ...,\n",
       "         [-25.4227, -25.0626, -27.5736,  ..., -29.2495, -29.2111, -26.1180],\n",
       "         [-20.1737, -20.5050, -23.1387,  ..., -25.3509, -24.2196, -20.6803],\n",
       "         [-49.3418, -49.4090, -51.9608,  ..., -56.9139, -56.5944, -51.0995]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Unembed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
    "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
    "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
    "    \n",
    "    def forward(self, normalized_resid_final):\n",
    "        # normalized_resid_final [batch, position, d_model]\n",
    "        \n",
    "        return einsum(\"batch position d_model, d_model d_vocab -> batch position d_vocab\", normalized_resid_final, self.W_U) + self.b_U\n",
    "\n",
    "rand_float_test(Unembed, [2, 4, 768])\n",
    "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950bb1d",
   "metadata": {},
   "source": [
    "## Full Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02d6ab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Tokens: torch.Size([2, 4])\n",
      "pos_embed: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Tokens: torch.Size([1, 35])\n",
      "pos_embed: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 50257])\n",
      "Reference output shape: torch.Size([1, 35, 50257])\n",
      "0.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ -43.4318,  -39.8365,  -43.0660,  ...,  -54.0878,  -54.3452,\n",
       "           -42.3645],\n",
       "         [-128.0392, -127.9935, -130.7010,  ..., -136.7122, -129.9262,\n",
       "          -129.3966],\n",
       "         [-119.8521, -121.0064, -123.8819,  ..., -128.5180, -126.6027,\n",
       "          -121.9061],\n",
       "         ...,\n",
       "         [-112.9815, -112.7749, -117.0633,  ..., -121.2914, -117.6574,\n",
       "          -114.5005],\n",
       "         [ -98.6724, -104.4888, -108.7361,  ..., -118.3552, -113.8766,\n",
       "          -106.3604],\n",
       "         [-126.8285, -128.9596, -128.3941,  ..., -140.1971, -138.5883,\n",
       "          -122.3698]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DemoTransformer(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = Embed(cfg)\n",
    "        self.pos_embed = PosEmbed(cfg)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
    "        self.ln_final = LayerNorm(cfg)\n",
    "        self.unembed = Unembed(cfg)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        # tokens [batch, position]\n",
    "        embed = self.embed(tokens)\n",
    "        pos_embed = self.pos_embed(tokens)\n",
    "        residual = embed + pos_embed\n",
    "        for block in self.blocks:\n",
    "            residual = block(residual)\n",
    "        normalized_resid_final = self.ln_final(residual)\n",
    "        logits = self.unembed(normalized_resid_final)\n",
    "        # logits have shape [batch, position, logits]\n",
    "        return logits\n",
    "\n",
    "rand_int_test(DemoTransformer, [2, 4])\n",
    "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
